\documentclass{amsart}
\usepackage{amsmath,amssymb,amsthm,mathrsfs,microtype}
\usepackage{minted}
\usepackage[margin=1in]{geometry}

\newtheorem{theorem}{Theorem}
\newtheorem{observation}[theorem]{Observation}
\newtheorem{lemma}[theorem]{Lemma}

\newcommand{\code}[1]{\mintinline{python}{#1}}

\newcommand{\CC}{\mathbb{C}}
\newcommand{\BB}{\mathbb{B}}
\newcommand{\ot}{\otimes}
\newcommand{\op}{\oplus}
\newcommand{\aaa}{\mathbf{a}}
\newcommand{\bbb}{\mathbf{b}}
\newcommand{\ccc}{\mathbf{c}}
\newcommand{\uuu}{\mathbf{u}}
\newcommand{\vvv}{\mathbf{v}}
\newcommand{\www}{\mathbf{w}}
\newcommand{\sss}{\mathbf{s}}

\title{Appendix: Border Apolarity Implementation}

\begin{document}
\maketitle
\section{Introduction}\label{sec:intro}
Given a tensor $T \in A \ot B\ot C$, a natural number $r$, and a reductive group
$G_T \subset \operatorname{GL}(A) \times \operatorname{GL}(B)
\times \operatorname{GL}(C)$ stabilizing $T$, this file implements complete
enumeration of candidate subspaces $F_{110}\subset T(C^*)^\perp \subset A^*\ot
B^*$ which (i) have codimension $r$ in $A^*\ot B^*$, (ii)
are fixed under the Borel $\BB_T$ of $G$, and (iii) which pass the (210) and (120)
tests. That is, for such $F_{110}$, the symmetrization maps
\begin{align}
&\label{f210} F_{110}\ot A^*\to S^2 A^*\ot B^* \text { and}\\
&\label{f120} F_{110}\ot B^*\to A^*\ot S^2 B^*
\end{align}
have image of codimension at least $r$. More precisely, we enumerate
the matrices representing such subspaces $F_{110}$ in fixed bases.
Such candidates may occur in positive dimensional families, so these matrices
may have entries in the coordinate ring of some affine variety.

The same computation with the roles of $A$, $B$, and $C$ permuted may be
performed to enumerate the candidate $F_{101}$ and $F_{011}$ subspaces.
Given a triple of candidates $(F_{110}, F_{101}, F_{011})$, a routine to apply
the (111)-test is provided. That is, the map
\begin{equation}\label{111map}
F_{110}\ot C^*\op F_{101}\ot B^*\op F_{011}\ot A^* \to A^*\ot B^*\ot C^*
\end{equation}
is implemented, and it may be checked if the codimension of its image is at
least $r$.

\subsection{Input description}\label{sec:input}

Choose bases of $A$, $B$ and $C$ consisting of weight vectors under the torus of
$G_T$. The tensor $T$ is described by its coefficients with respect to these
bases. The action of $\BB_T$ is described by the weights of the basis vectors
along with the representations $\mathfrak{n} \to
\mathfrak{gl}(A)$, $\mathfrak{n} \to \mathfrak{gl}(B)$, and $\mathfrak{n} \to
\mathfrak{gl}(C)$. Concretely, Representations of $\mathfrak{n}$ are described
by giving the matrix of the action of the simple root vectors in the
distinguished bases.

\subsection{Software used}

The code is written in Python 3, using the libraries provided by SageMath. It
has been tested with SageMath 9.5.

\section{Program Listing}

<<complete=False>>=
from sage.all import *
from itertools import product,combinations

@
\subsection{Top level routines}
Apply the ideal enumeration algorithm up to the $(111)$-test, assuming $T$ has
cyclic symmetry. Cyclic symmetry is used to avoid the computation of the $(101)$
and $(011)$ candidates.
<<complete=False>>=
def border_apolarity_cycl_inv(T,reps,r):
    # Check that the data of reps actually stabilize $T$ and compute the simple roots
    simple_roots = check_T_is_stabilized(T,reps)
    # Find the representation data for $T(C^*)^\perp$ and report the matrix of
    # the embedding into $A^*\ot B^*$
    reptp,em = Tperp_rep_and_embedding(T,reps) # Find teh weight diagram of $T(C^*)^\perp$
    wtd = weight_diagram(reptp,simple_roots)

    a = len(T)
    b = T[0].nrows()
    cand110 = []

    # Enumerate Borel fixed subspace families of $T(C^*)^\perp$. These are given
    # by matrices Stperp over a polynomial ring and a corresponding ideal I the
    # coefficients of Stperp are considered modulo, i.e., the family takes
    # parameters in $V(I)$.
    for Stperp,I in borel_fixed_subspaces(wtd, em.nrows()-r):
        # Embed into $A^*\ot B^*$
        Sab = em*Stperp

        # Restrict to the closed subset of $V(I)$ passing the $(210)$ test
        S210 = matrix_11_to_21(Sab,a)
        I = minors_ideal(S210, S210.nrows() - r + 1, I)

        # Restrict to the closed subset of $V(I)$ passing the $(120)$ test
        S120 = matrix_11_to_21(transpose_tensor(Sab,a),b)
        I = minors_ideal(S120, S120.nrows() - r + 1, I)

        # Check if the family is nonempty
        if QQ(1) not in I:
            # If there is a single solution in the family add it to cand110,
            # otherwise raise an error. This is sufficient for $M_{\langle 3\rangle}$ and $\operatorname{det}_3$, 
            # and more generally one can go on to apply the $(111)$ test to
            # parameterized families of candidate triples
            cand110.append(Sab.apply_map(lambda e: QQ(I.reduce(e)), QQ))

    cand111 = []
    for xs in product(*map(enumerate,[cand110]*3)):
        ixs = tuple(i for i,x in xs)
        if ixs != min([ixs,ixs[1:]+ixs[:1],ixs[2:]+ixs[:2]]):
            # Skip triples equal to others we check modulo cyclic permutation
            continue
        print(ixs,end=' ')
        sys.stdout.flush()

        W = matrix_to_111(*[x for _,x in xs])
        if W.rank() <= W.dimensions()[0] - r:
            cand111.append(W)
    return cand111,cand110

@

Given $T\in A\ot B\ot C$ and the representations of $A$, $B$, and $C$, this
function checks checks the input data for correctness in various ways (see the 
inline notes), and also computes the simple roots implied by the representation data.
<<complete=False>>=
def check_T_is_stabilized(T,reps):
    a = len(T)
    b,c = T[0].dimensions()

    # There is one weight for each basis vector
    assert all(len(wts) == d for d,(wts,_) in zip((a,b,c),reps))
    # The given representations of $\mathfrak{n}$ operate on the correct dimensional space
    assert all(x.nrows() == d and x.ncols() == d 
            for d,(_,xs) in zip((a,b,c),reps) for x in xs)

    # compute roots of the simple roots vectors xs
    simple_roots = []
    for xi in range(len(reps[0][1])):
        for wts,xs in reps:
            if not xs[xi].is_zero():
                i,j = xs[xi].nonzero_positions()[0]
                simple_roots.append(wts[i] - wts[j])
                break

    # Check xs are actally root vectors for the corresponding roots and that 
    # the simple roots agree for each rep in reps
    for wts,xs in reps:
        assert len(simple_roots) == len(xs)
        for root,x in zip(simple_roots,xs):
            for i,j in x.nonzero_positions():
                assert wts[i]-wts[j] == root

    # Check T is weight zero in $A\ot B\ot C$
    for i,m in enumerate(T):
        for j,k in m.nonzero_positions():
            assert (reps[0][0][i] + reps[1][0][j] + reps[2][0][k]).is_zero()
    
    # Check T is closed under $\mathfrak{n}$
    (_,xsA), (_,xsB), (_,xsC) = reps
    for xa,xb,xc in zip(xsA, xsB, xsC):
        xaT = [sum(xa[i,j] * T[j] for j in range(a)) for i in range(a)]
        xbT = [xb*m for m in T]
        xcT = [m*xc.T for m in T]
        # we should have xaT + xbT + xcT = 0
        assert all((m1+m2+m3).is_zero() for m1,m2,m3 in zip(xaT, xbT, xcT))
    
    return simple_roots
@

\subsection {$\BB$-fixed subspace enumeration}

For a module $M$, $\BB$-fixed subspaces are parameterized by a choices of 
subspaces $S_\lambda \subset M_\lambda$ where $x. S_\lambda \subset S_\mu$ for
every raising operator $x$ corresponding to an arrow $M_\lambda \to M_\mu$ in the
weight diagram (see \S2.5.2 of the article). This parameterization is composed
of two components, the combinatorial data $d_\lambda =
\operatorname{dim} S_\lambda$, and the subvariety $Y_{d_\lambda}$ of the product of
Grassmannians $X_{d_\lambda} = \prod_{\lambda} Gr(M_\lambda,d_\lambda)$ corresponding to
the condition on weight diagram arrows above.

For fixed $D$, most assignments $\lambda \mapsto d_\lambda$ satisfying
$\sum_\lambda d_\lambda = D$ have $Y_d = \varnothing$, and to explicitly check
each such $d_\lambda$ would be impossible. Hence, we investigate only such assignments
$d_\lambda$ satisfying necessary conditions for $Y_d\ne \varnothing$. These conditions
take the form of linear inequalities. Thus, the assignments
we explicitly consider occur as the set of integer points of a
polytope, which can be efficiently enumerated.


% We may parameterize the $\fb_T$ fixed subspaces $M$ of dimension $d$ as follows: Fix an assignment of dimensions $d_\lambda$, $0\le d_\lambda \le \tdim M_\lambda$,
% $\sum_\lambda d_\lambda = d$. Choices of $S_\lambda$ with $\dim S_\lambda = d_\lambda$ are
% parameterized by the product of Grassmannians $X = \prod_{\lambda} G(M_\lambda,d_\lambda)$.
% Given a raising operator $x$ corresponding to an arrow $M_\lambda \to M_\mu$ in the
% weight diagram, the condition that $x. S_\lambda
% \subset S_{\mu}$ is an explicit polynomial condition on $X$. Cutting
% $X$ by all such polynomials gives a description of the set of $\fb_T$ fixed
% subspaces with $\dim S_\lambda = d_\lambda$ (which can be empty). All Borel fixed
% subspaces are obtained as $d_\lambda$ ranges over all such assignments.
% In small examples, a complete list of $\fb_T$ fixed subspaces may frequently be
% read off of the weight diagram.

This function returns a generator yielding the set of highest weight vectors 
of the grassmannian, each possibly parameterized (having entries in a
polynomial ring modulo an ideal). The grassmannian planes are represented 
as the column space of matrices.
<<complete=False>>=
# mdata is the information for the module as summarized by weight_decomposition
# subdim determines which grassmannian to consider (the dimension of the returned spaces)
def borel_fixed_subspaces(wtd,D,verbose=True):
    for i,dlambda in enumerate(possible_dim_assignments(wtd,D)):
        if verbose:
            print(i,end=' ')
        for S in borel_fixed_subspaces_dlambda(wtd,dlambda,verbose):
            yield S

@
Given a weight diagram and an assignment $\lambda \mapsto d_\lambda$, this
function enumerates corresponding matrices corresponding to $Y_{d_\lambda}$.

A Grassmannian $Gr(V,s)$ may be represented in bases as $s\times \vvv$ matrix
modulo the left action of $\operatorname{GL}(s)$. A normal form for this
action is ordinary echelon form of the matrix, so $Gr(V,s)$ may be written as a
disjoint union of affine spaces according to the pivot columns of echelon forms.

Thus, the set $X_{d_\lambda}$ is parameterized by combinations of such choices
of pivot columns in each weight space. This function looks at each of these and
computes the variety corresponding to the intersection with $Y_{d_\lambda}$. 
A list of matrices with entries in the coordinate ring modulo these
$Y_{d_\lambda}$ equations is returned.

<<complete=False>>=
def borel_fixed_subspaces_dlambda(wtd,dlambda,verbose=False):

    dlist = [(wt,d,len(wtd.get_vertex(wt))) for wt, d in dlambda.items()]

    if verbose: 
        missing = [wt for wt,d in dlambda.items() if d < len(wtd.get_vertex(wt))]
        missing.sort(key=lambda wt: (sum(wt),wt))
        print('grass hwv missing',missing)


    if all(m == f or m == 0 for wt,m,f in dlist):
        # $S$ is full in full in every weight space for which it is nonzero.
        # Such a set satisfies the weight diagram arrow conditions due to the
        # necessary conditions on $d_{\lambda}$. No need to check again
        yield (identity_matrix(QQ, sum(f for _,_,f in dlist))[:,
                [i for wt,m,f in dlist if m == f for i in wtd.get_vertex(wt)]],QQ.ideal(0))
        return

    # Otherwise, we need parameters. Here we check all combinations of choices
    # of pivot columns in each grassmannian

    for nzsi,nzs in enumerate(product(*[combinations(range(f),m) for wt,m,f in dlist])):

        if verbose:
            print(nzsi,end=' ')
            sys.stdout.flush()

        nvars = sum( (nzi+1)*(j-i-1) for (wt,m,f),nz in zip(dlist,nzs)
            for nzi,(i,j) in enumerate(zip(nz,nz[1:]+(f,))))
        R = PolynomialRing(QQ,'t',nvars,implementation='singular') if nvars > 0 else QQ

        S = {}
        xi = 0
        for (wt,m,f),nz in zip(dlist,nzs):
            t = matrix(R,f,m,sparse=True)
            t[nz,:] = identity_matrix(R,m,sparse=True)
            for j,ks in enumerate(zip(nz,nz[1:]+(f,))):
                inc = (ks[1]-ks[0]-1)*(j+1)
                t[ks[0]+1:ks[1],:j+1] = matrix(R,ks[1]-ks[0]-1,j+1,R.gens()[xi:xi+inc])
                xi += inc 

            S[wt] = (t, nz) # remember the pivots for equations below

        # Now restrict the parameters appearing so that $S$ is closed under the
        # arrows of the weight diagram
        eqs = []
        for wta,wtb,x in wtd.edges():
            S1,_ = S[wta]
            S2,S2pvts = S[wtb]
            # Reduce the columns of xS1 modulo S2 using the pivots of S2.
            xS1 = (x*S1).T
            S2 = S2.T
            for i,j in enumerate(S2pvts):
                for k in xS1.nonzero_positions_in_column(j):
                    xS1[k] -= xS1[k,j]*S2[i]
            # xS1 now is in a normal form modulo S2, so the equations of
            # containment are the conditions that xS1 == 0
            eqs.extend(xS1.dict().values())

        I = R.ideal(eqs)
        if R.one() in I:
            continue

        Smat = block_diagonal_matrix([S[wt][0] for wt,_,_ in dlist],sparse=True)

        ix = [i for wt,_,_ in dlist for i in wtd.get_vertex(wt)]
        ixi = [None]*len(ix)
        for j,i in enumerate(ix):
            ixi[i] = j
        Smat = Smat[ixi,:]

        yield (Smat,I)

    if verbose: 
        print()

@
Given a weight diagram \code{wtd} and a target dimension \code{dim}, this
function computes the integer points $d_\lambda$ of the polytope corresponding
to the following necessary conditions that assignments $d_\lambda$ have
$Y_{d_\lambda}\ne \varnothing$ (and $\sum_\lambda d_\lambda = \code{dim}$):
\begin{enumerate}
\item \label{primal} Suppose that $M_\mu \to M_{\lambda_i}$ in the weight diagram, where
$\lambda_i$ ranges over some set of weights. The map 
$y : M_\mu \to \bigoplus_{i} M_{\lambda_i}$ 
satisfies 
$y (S_\mu) \subset \bigoplus_{i} S_{\lambda_i}$. 
In particular, 
$d_\mu \le \operatorname{dim} \operatorname{ker} y + \sum_{i}
d_{\lambda_i}$.

\item \label{dual} Dually, suppose that $M_{\mu_i} \to M_\lambda$ in the weight diagram, where
$\mu_i$ ranges over some set of weights. The map 
$z : M_\lambda^* \to \bigoplus_{i} M_{\mu_i}^*$ 
satisfies 
$z (S_\lambda^\perp) \subset \bigoplus_{i} S_{\mu_i}^\perp$. 
In particular, 
$\operatorname{dim}M_\lambda - d_\lambda \le \operatorname{dim}
\operatorname{ker} z + \sum_{i}
\operatorname{dim}(M_{\mu_i}) - d_{\mu_i}$.

\item \label{composition} One can apply the previous conditions to compositions of arrows in the
weight diagram. We use only the condition corresponding to a single 
arrow $w : M_\mu \to M_\nu \to M_\lambda$. For a single arrow, conditions \eqref{primal}
        and \eqref{dual} are the same: $d_\mu \le
        \operatorname{ker}\operatorname{dim} w + d_\lambda$.
\end{enumerate}
<<complete=False>>=
def possible_dim_assignments(wtd,dim):
    lp = MixedIntegerLinearProgram()
    for wt in wtd:
        lp.set_min(lp[wt],0)
        lp.set_max(lp[wt],len(wtd.get_vertex(wt)))

    lp.add_constraint(lp.sum(lp[wt] for wt in wtd) == dim)

    for wt in wtd:
        # Condition $\eqref{primal}$
        for k in range(1,len(wtd.outgoing_edges(wt))+1):
            for es in combinations(wtd.outgoing_edges(wt),k):
                kdim = block_matrix([[xr] for _,_,xr in es]).right_kernel().dimension()
                lp.add_constraint(lp[wt] <= kdim + lp.sum(lp[wtr] for _,wtr,_ in es))

        # Condition $\eqref{dual}$
        # This when $k = 1$ occurs also for condition $\eqref{primal}$ as well, so we skip it.
        for k in range(2,len(wtd.incoming_edges(wt))+1):
            for es in combinations(wtd.incoming_edges(wt),k):
                cokdim = block_matrix([[-xr.transpose()] 
                    for _,_,xr in es]).right_kernel().dimension()
                lp.add_constraint(len(wtd.get_vertex(wt)) - lp[wt] <= cokdim + lp.sum(
                    len(wtd.get_vertex(wtl)) - lp[wtl] for wtl,_,xr in es))

    # Condition $\eqref{composition}$
    for wtstart in wtd:
        for _,wtmid,x1 in wtd.outgoing_edges(wtstart):
            for _,wtlast,x2 in wtd.outgoing_edges(wtmid):
                kdim = (x2*x1).right_kernel().dimension()
                lp.add_constraint(lp[wtstart] <= kdim + lp[wtlast])

    # We have computed the polytope, now enumerate the integer points

    # Fix an ordering of the weights $\lambda_i$
    wts = wtd.topological_sort()

    # Given assignments of $d_{\lambda_j}$, $j\le i-1$, set $d_{\lambda_i}$ to the values for which the 
    # polytope still intersects the coordinate hyperplane corresponding to the
    # current partial assignment and recursively apply this procedure.
    from sage.numerical.mip import MIPSolverException
    def dfs(i):
        if i == len(wts):
            # We have set all coordinates to integer values and remain in the
            # polytope, report this as a solution
            yield {wt : int(lp.get_min(lp[wt])) for wt in wts}
            return
        wt = wts[i]
        mult = int(lp.get_max(lp[wt]))
        for dcur in range(0, mult+1):
            lp.set_min(lp[wt],dcur)
            lp.set_max(lp[wt],dcur)
            try:
                # The polytope has nonzero intersection with set corresponding
                # to fixing the first $i$ coordinates as we have. Recursively try 
                # to set the remaining coordinates and report all solutions.
                lp.solve()
                for pt in dfs(i+1):
                    yield pt
            except MIPSolverException:
                # There are no points in the polytope with the first $i$
                # coordinates fixed to the values we have used. Don't search
                # further.
                pass
        lp.set_min(lp[wt],0)
        lp.set_max(lp[wt],mult)

    return dfs(0)

@
\subsection{$(210)$ and $(120)$ symmetrization maps, $(111)$ addition map}

If $B$ is the $\aaa \bbb\times \vvv$ matrix of a map $V \to A\ot B$ with respect
to an lexicographically ordered basis of $A\ot B$ of the form $a_i \ot b_j$,
this routine computes the matrix of the map $V \ot A \to S^2 A\ot B$. The bases
of the tensor products are also lexicographically ordered tensor
products. The basis $a_ia_j$, $i\le j$, of $S^2 A$ is ordered reverse
lexicographically: $a_{i_1}a_{j_1} $ comes before $a_{i_2}a_{j_2}$ if either
$j_1 < j_2$ or $j_1=j_2$ and $i_1 < i_2$.
<<complete=False>>=
def matrix_11_to_21(B,a):
    b = B.dimensions()[0] // a
    S = B.dimensions()[1]
    W = {}
    # i,k < a
    # j < b
    # s < S
    for I,s in B.nonzero_positions():
        i,j = I // b, I % b
        v = B[I,s]
        for k in range(a):
            mi,ma = min(i,k),max(i,k)
            ix = (( binomial(ma+1,2)+mi )*b+j,s*a+k)
            W[ix] = W.get(ix,0) + v
    W = matrix(B.base_ring(),binomial(a+1,2)*b,S*a,W)
    return W

@
Suppose $A$,$B$, and $C$ are $\bbb\ccc \times \sss$, $\ccc\aaa \times \uuu$, and
$\aaa\bbb \times \vvv$ matrices corresponding to maps $S \to B\ot C$, $U\to C\ot
A$, $V\to A\ot B$, respectively. It is assumed that all tensor products are
given with respect to lexicograpcally ordered product bases. This routine
computes the matrix corresponding to the addition map 
$ A\ot S \op B\ot U \op C \ot V \to A\ot B\ot C$. Here tensor products are
given by lexicographically ordered product bases, and the basis of the direct sum
is the concatenation of the bases of the summands.
<<complete=False>>=
def matrix_to_111(A,B,C):
    a = int(sqrt(B.dimensions()[0]*C.dimensions()[0]/A.dimensions()[0]))
    b = C.dimensions()[0] // a
    c = B.dimensions()[0] // a
    W = {}
    for i in range(a):
        for I,l in A.nonzero_positions():
            j,k = I // c, I % c
            W[((i*b+j)*c+k, i*A.dimensions()[1]+l)] = A[j*c+k,l]
    for j in range(b):
        for I,l in B.nonzero_positions():
            k,i = I // a, I % a
            W[((i*b+j)*c+k, a*A.dimensions()[1] + j*B.dimensions()[1]+l)] = B[k*a+i,l]
    for k in range(c):
        for I,l in C.nonzero_positions():
            i,j = I // b, I % b
            W[((i*b+j)*c+k, a*A.dimensions()[1] + b*B.dimensions()[1] +\
                    k*C.dimensions()[1]+l)] = C[i*b+j,l]
    W = matrix(A.base_ring(),a*b*c,a*A.dimensions()[1]+b*B.dimensions()[1]+c*C.dimensions()[1],W)
    return W

@

Given an $\aaa \bbb \times \sss$ matrix representing a map $S \to A\ot B$,
returns the matrix of the same size corresponding to the map $S\to B\ot A$.
Bases of tensor products are assumed to be lexicographically ordered product
bases.
<<complete=False>>=
def transpose_tensor(B,a):
    b = B.dimensions()[0] // a
    S = B.dimensions()[1]
    Bp = {}
    for I,k in B.nonzero_positions():
        i,j = I // b, I % b
        Bp[(j*a+i,k)] = B[I,k]
    return matrix(B.base_ring(),B.dimensions()[0],B.dimensions()[1],Bp)

@

\subsection{Representation manipulation}
Given $T\in A\ot B\ot C$ and the representations of $A$, $B$, and $C$, this
function computes the representation of $T(C^*)^\perp \subset A^*\ot B^*$ and
the matrix of the embedding of the distinguished weight bases of these modules.
Optionally, the parameter \code{missing} may be set to $0$ to instead compute
this information for $T(A^*)^\perp \subset B^*\ot C^*$ or to $1$ to do this for  
$T(B^*)^\perp \subset C^*\ot A^*$.
<<complete=False>>=
def Tperp_rep_and_embedding(T,reps,missing=2):
    reps = reps[missing+1:] + reps[:missing]
    repAB = module_product(*[module_dual(rep) for rep in reps])

    Tcycl = T
    for i in range(missing):
        Tcycl = tensor_cycl(Tcycl)
    Tflattening = matrix(QQ,[m.list() for m in Tcycl],sparse=True)
    em = Tflattening.right_kernel_matrix().transpose().sparse_matrix()

    reptp = submodule_from_basis(repAB,em)
    return reptp,em

@
When \code{repa} and \code{repb} describe the representations of $V$, and $W$,
respectively this function computes description of the representation of $V\ot
W$. The distinguished weight basis of the tensor product is $v_i \ot w_j$
ordered lexicographically, where $w_i$ and $w_j$ are the distinguished weight
bases of $V$ and $W$, respectively. 
<<complete=False>>=
def module_product(repa,repb):
    wtsa, xsa = repa
    wtsb, xsb = repb
    wtsab = [wta + wtb for wta,wtb in product(wtsa,wtsb)]
    xsab = []
    for xa,xb in zip(xsa,xsb):
        xab = xa.tensor_product(identity_matrix(QQ,xb.nrows()))
        xab += identity_matrix(QQ,xa.nrows()).tensor_product(xb)
        xsab.append(xab)
    return (wtsab,xsab)

@
When \code{rep} describe the representation of $V$,
this function computes the description of the representation $V^*$.
The distinguished weight basis of $V^*$ is the dual basis of that of $V$.
<<complete=False>>=
def module_dual(rep):
    wts, xs = rep
    wtsd = [-wt for wt in wts]
    xsd = [-x.transpose() for x in xs]
    return (wtsd,xsd)

@
Here, \code{rep} describes the representation of $V$, and \code{em} is an $\vvv \times
\www$ matrix containing as columns a weight basis of a submodule $W$ of $V$,
e.g., it is the matrix of the embedding $W\to V$.
This function computes the description of the representation $W$ with respect to
this basis. The facts that $B$ describes a weight basis and that $W$ is a
$\BB$-submodule of $V$ are checked.
<<complete=False>>=
def submodule_from_basis(rep,em):
    wts, xs = rep

    # check em describes a basis
    assert em.rank() == em.ncols()

    wtsw = []
    # check the columns of em are weight vectors and find their weights
    for v in em.columns():
        wt = wts[v.nonzero_positions()[0]]
        assert all(wt == wts[j] for j in v.nonzero_positions())
        wtsw.append(wt)

    xsw = []
    # check $W$ is fixed under the simple root vectors and compute the matrix of
    # their action
    for x in xs:
        # find y solving x*em == em*y, and raises an error if there is none
        y = em.solve_right(x*em) 
        # Since em is basis, the eqution x*em == em*y is sufficient to
        # guarantee the claims
        xsw.append(y)

    return (wtsw,xsw)

@
Given a representation \code{rep} and the set of simple roots consistent with
it, this routine computes the corresponding weight diagram, a directed graph
with vertices labelled by weights and with edges labelled with the matrix of the restriction
of the corresponding raising operator. Each vertex records the ordered list of
corresponding distinguished weight basis vectors (with respect to which the edge
matrices are given).
<<complete=False>>=
def weight_diagram(rep,simple_roots):
    # tot = simultaneous_eigenspace(a[2])
    wts, xs = rep
    dim = len(wts)

    assert all(x.nrows() == dim and x.ncols() == dim for x in xs)

    wtd = DiGraph()
    for bi,wt in enumerate(wts):
        wt.set_immutable()
        if wt not in wtd:
            wtd.add_vertex(wt)
            wtd.set_vertex(wt,[])
        wtd.get_vertex(wt).append(bi)

    for wt in wtd:
        wt.set_immutable()
        for root,x in zip(simple_roots,xs):
            wt_raised = wt + root
            wt_raised.set_immutable()
            if wt_raised in wtd:
                wtd.add_edge(wt,wt_raised,
                        x[wtd.get_vertex(wt_raised),wtd.get_vertex(wt)])
    
    return wtd

@
\subsection{Efficiently computing the ideal of $r\times r$ minors}

Given an integer $r$ and a matrix $m$ with entries in a polynomial ring interepreted modulo the
ideal $I$, an ideal $J\supset I$ is computed which set theoretically cuts out
the closed set $X$ on which $m$ has rank at most $r-1$. That is, if $I_r$ is the
ideal generated by the $r\times r$ minors of $m$, then $I_r+I \subset J \subset
\sqrt{I_r+I}$.

This routine attempts to compute such a $J$ without enumerating all of the
$r\times r$ minors of $m$, which may be cost prohibitive. The algorithm used is
essentially row reduction by units modulo $I$. When such reduction cannot
proceed, a nonzero coefficient $f$ of the matrix is heuristically selected and
the algorithm recursively analyzes two cases according to the decomposition $X =
(X\cap V(f)) \cup (X\setminus V(f))$. Algebraicly, the first case corresponds to
continuing the computation with $I$ replaced with $I+(f)$, and the second case
corresponds to continuing the computation in the polynomial ring localized at
$f$. If $S$ is the polynomial ring over which $m$ and $I$ are defined,
localization is implemented by working in the ring $R = S[d]$, $d$ an additional
indeterminant, with $I$ replaced by $I + (df-1)$. 

Since the algorithm is recursive, all computations are done in the ring $R$ and
the current element $d_0$ associated to the inverse of $d$ is remembered. When
it is needed to localize with respect to an additional element $f$, $d$ is
reinterpreted as the inverse of $d_0f$ by substuting $d$ with $df$ in the
enteries of $m$ and replacing $I$ with $I\cap S + (dd_0f - 1)$.

<<complete=False>>=
def minors_ideal(m,r,I=None):
    from collections import Counter

    S = m.base_ring()
    if I is None: I = S.ideal()

    if S is QQ:
        return QQ.ideal(1) if QQ(1) in I or m.rank() >= r else QQ.ideal(0)

    R = PolynomialRing(S.base_ring(),S.gens()+('d',))
    dv = R.gens()[-1]

    def rec(m,I,d,r):
        if m.is_zero():
            return I.elimination_ideal(dv).change_ring(S)
        if r == 1:
            return (I + m.coefficients()).elimination_ideal(dv).change_ring(S)

        # select the most common nonzero element of 
        f = Counter(m.dict().values()).most_common(1)[0][0]

        # Case 1: pass to the closed set where f == 0
        Icur = I + f
        mcur,lo = elimination_by_units(m,Icur)
        I1 = rec(mcur[lo:,lo:],Icur,d,r-lo) if lo < r else S.ideal(1)

        # Case 2: pass to the open set where f not identically zero, e.g., localize at f
        mcur = m.subs({dv : dv*f})
        Icur = I.elimination_ideal(dv) + [dv*d*f-1]
        mcur,lo = elimination_by_units(mcur,Icur)
        I2 = rec(mcur[lo:,lo:],Icur,d*f,r-lo) if lo < r else S.ideal(1)

        # Combine the result of both cases: $I_1\cap I_2$ corresponds to the
        # union of the corresponding parameter sets
        return I1.intersection(I2)

    return rec(m.change_ring(R), I.change_ring(R), R.one(), r)

@
This routine implements row elimination by unit coefficients of $m$ mod $I$
with column pivoting. It returns the resulting matrix $m'$ and a number $r$. 
$m'$ has the form
\[
\begin{bmatrix}
T & A \\
0 & B
\end{bmatrix},
\]
where $T$ is $r\times r$, upper triangular, with ones on the diagonal, and $B$
contains no unit coefficients.
<<complete=False>>=
def elimination_by_units(m,I):
    m = m.apply_map(lambda e: I.reduce(e))

    from sage.libs.singular.function import singular_function
    lift = singular_function('lift')

    # computes the inverse mod $I$ if it exists, otherwise None
    def try_inverse(e):
        try:
            return lift(I+e,1).list()[-1]
        except RuntimeError:
            return None

    r = 0
    while True:
        if r == min(m.nrows(),m.ncols()):
            break

        einv = None
        for (i,j),e in m[r:,r:].dict().items():
            einv = try_inverse(e)
            if einv is not None:
                break
        if einv is None:
            break
        i += r
        j += r

        m.swap_rows(r,i)
        m.swap_columns(r,j)
        m[r,:] *= einv
        for k in m.nonzero_positions_in_row(r):
            m[r,k] = I.reduce(m[r,k])
        assert m[r,r] == 1
        for i in m.column(r)[r+1:].nonzero_positions():
            i += r+1
            m.add_multiple_of_row(i,r,-m[i,r])
            for k in m.nonzero_positions_in_row(i):
                m[i,k] = I.reduce(m[i,k])
        r += 1

    return m,r
  


@
\subsection{Miscellaneous}
When $T\in A\ot B\ot C$, this function cyclicly permutes the factors to obtain a
matrix $T\in B\ot C\ot A$. 
<<complete=False>>=
def tensor_cycl(T):
    m = len(T)
    n,s = T[0].dimensions()
    S = [zero_matrix(QQ,s,m) for i in range(n)]
    for i,j,k in product(range(m),range(n),range(s)):
        S[j][k,i] = T[i][j,k]
    return S
@
\end{document}
